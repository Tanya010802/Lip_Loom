# Lip_Loom
LIP LOOM : Deep Learning Model for Lip Reading

Project Overview:
Lip Loom is a pioneering project aimed at enhancing multimedia accessibility through the development of a Deep Learning Model for lip reading. Leveraging the power of Python and TensorFlow, our team has crafted a versatile model capable of not only generating accurate subtitles but also contributing to language translation and content summarization.


Key Features:

Robust lip movement recognition using spatiotemporal neural networks.
Real-time processing optimization for quick and accurate lip reading.
User-centric design for enhanced accessibility.
Project Objectives:

Create a Stable Lip-Reading Model: Design and implement a Sequential architecture for reliable lip movement recognition.
Optimize Processing in Real Time: Ensure quick and accurate lip reading for live applications.
Implement User-Centric Design: Craft a user-friendly interface for individuals with hearing impairments.
Methodology:
The project involves data collection, preprocessing, and model development using Python and TensorFlow. The lip reading model architecture includes Conv3D layers, Bidirectional LSTMs, and optimization using the Adam optimizer.


DATA SET - The Oxford-BBC Lip Reading in the Wild (LRW) dataset serves as a foundational component for training and evaluating the deep learning model in this project.
